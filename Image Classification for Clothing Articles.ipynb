{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Image Classification for Clothing Articles.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Image Classification of Clothing Articles by Adam Astor\n","\n","The dataset I will work with for this project is called Fashion MNIST. It is preloaded into Tensorflow and separately can be found at the link below:\n","\n","https://keras.io/api/datasets/\n","\n","About this Dataset: Fashion-MNIST is a dataset of Zalando's article imagesâ€”consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. Zalando intends Fashion-MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits.\n","\n","This project aims to train a machine learning model that is able to accurately classify articles of clothing it has never seen before. The data includes ten classes for different types of clothing commonly seen and worn around the world. Once the project is complete, there are many use cases where this model will be helpful including security, inventory, and disability-related services."],"metadata":{"id":"KpGadxNbi0Pm"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ypjbBjBEgyoe"},"outputs":[],"source":["import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","from tensorflow.keras.datasets import fashion_mnist\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.models import Sequential \n","from tensorflow.keras.layers import Dense\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split, cross_val_score\n","from sklearn.metrics import classification_report,confusion_matrix\n","\n","from tensorflow.keras import optimizers"]},{"cell_type":"code","source":["#1.  Spit data into training and test sets\n","(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n","\n","#2. Preprocess data to put it into ANN models\n","input_dim = 784  # 28*28\n","output_dim = nb_classes = 10\n","nb_epoch = 20\n","\n","X_train = X_train.reshape(60000, input_dim)\n","X_test = X_test.reshape(10000, input_dim)\n","X_train = X_train.astype('float32')\n","X_test = X_test.astype('float32')\n","X_train /= 255\n","X_test /= 255\n","\n","Y_train = to_categorical(y_train, nb_classes)\n","Y_test = to_categorical(y_test, nb_classes)"],"metadata":{"id":"3ZOwOms6hOUP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655398870396,"user_tz":420,"elapsed":1878,"user":{"displayName":"Adam Astor","userId":"10506171213258147392"}},"outputId":"1eb3b5f3-99d5-4c2f-af0c-6408f9f1a07d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n","32768/29515 [=================================] - 0s 0us/step\n","40960/29515 [=========================================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n","26427392/26421880 [==============================] - 0s 0us/step\n","26435584/26421880 [==============================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n","16384/5148 [===============================================================================================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n","4423680/4422102 [==============================] - 0s 0us/step\n","4431872/4422102 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"markdown","source":["First, we will tune the number of layers in our model to see what works best.\n","\n","Implement a three layer ANN model with 128, 64 and 10 neurons in the layers using 8 as the mini batch size."],"metadata":{"id":"6YpwqnynmbaL"}},{"cell_type":"code","source":["model = Sequential()\n","# our first dense layer\n","model.add(Dense(128, input_shape=(784,), activation=\"relu\"))\n","# our second dense layer\n","model.add(Dense(64, activation=\"relu\"))\n","# last layer is the output layer.\n","model.add(Dense(10, activation=\"softmax\"))\n","\n","model.compile(optimizer='sgd', loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","# setting verbose=1 prints out some results after each epoch\n","model.fit(X_train, Y_train, batch_size=8, epochs=20, verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":487},"id":"Zbzs0P1HhW1X","executionInfo":{"status":"error","timestamp":1654295719582,"user_tz":420,"elapsed":31344,"user":{"displayName":"Adam Astor","userId":"10506171213258147392"}},"outputId":"9bffc5f6-07ab-42a3-95a9-8eb911e9494a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","7500/7500 [==============================] - 15s 2ms/step - loss: 0.5641 - accuracy: 0.8042\n","Epoch 2/20\n","7500/7500 [==============================] - 14s 2ms/step - loss: 0.4090 - accuracy: 0.8530\n","Epoch 3/20\n"," 802/7500 [==>...........................] - ETA: 12s - loss: 0.3829 - accuracy: 0.8599"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-64-17d4b586079e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# setting verbose=1 prints out some results after each epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["score = model.evaluate(X_test, Y_test, verbose=0)\n","print('Test score:', score[0])\n","print('Test accuracy:', score[1])"],"metadata":{"id":"o2HxZb5mmt9m"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Implement a four layer ANN model with 128, 64, 32 and 10 neurons in the layers using 8 as the mini batch size."],"metadata":{"id":"t9CdpYlGn9Wg"}},{"cell_type":"code","source":["model = Sequential()\n","# our first dense layer\n","model.add(Dense(128, input_shape=(784,), activation=\"relu\"))\n","# our second dense layer\n","model.add(Dense(64, activation=\"relu\"))\n","# our third dense layer\n","model.add(Dense(32, activation=\"relu\"))\n","# last layer is the output layer.\n","model.add(Dense(10, activation=\"softmax\"))\n","\n","model.compile(optimizer='sgd', loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","# setting verbose=1 prints out some results after each epoch\n","model.fit(X_train, Y_train, batch_size=8, epochs=20, verbose=1)"],"metadata":{"id":"4ezA_1EVm3aP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["score = model.evaluate(X_test, Y_test, verbose=0)\n","print('Test score:', score[0])\n","print('Test accuracy:', score[1])"],"metadata":{"id":"nQeQ_x-Gn_kz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Implement a five layer ANN model with 128, 64, 64, 32 and 10 neurons in the layers using 8 as the mini batch size."],"metadata":{"id":"pSzy5uEZrUNO"}},{"cell_type":"code","source":["model = Sequential()\n","# our first dense layer\n","model.add(Dense(128, input_shape=(784,), activation=\"relu\"))\n","# our second dense layer\n","model.add(Dense(64, activation=\"relu\"))\n","# our third dense layer\n","model.add(Dense(64, activation=\"relu\"))\n","# our fourth dense layer\n","model.add(Dense(32, activation=\"relu\"))\n","# last layer is the output layer.\n","model.add(Dense(10, activation=\"softmax\"))\n","\n","model.compile(optimizer='sgd', loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","# setting verbose=1 prints out some results after each epoch\n","model.fit(X_train, Y_train, batch_size=8, epochs=20, verbose=1)"],"metadata":{"id":"CjvJeE4loCEq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["score = model.evaluate(X_test, Y_test, verbose=0)\n","print('Test score:', score[0])\n","print('Test accuracy:', score[1])"],"metadata":{"id":"mb3Qo44WrX3m"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["While the five-layer models performance improved over the four-layer model, the progress seems to be tapering off. I will continue on to test the activation functions used for the non-output layers. We started with all Relu functions, now I will test Hyperbolic Tangent (tanh)."],"metadata":{"id":"Czmm1VDjs1cP"}},{"cell_type":"code","source":["model = Sequential()\n","# our first dense layer\n","model.add(Dense(128, input_shape=(784,), activation=\"tanh\"))\n","# our second dense layer\n","model.add(Dense(64, activation=\"tanh\"))\n","# our third dense layer\n","model.add(Dense(64, activation=\"tanh\"))\n","# our fourth dense layer\n","model.add(Dense(32, activation=\"tanh\"))\n","# last layer is the output layer.\n","model.add(Dense(10, activation=\"softmax\"))\n","\n","model.compile(optimizer='sgd', loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","# setting verbose=1 prints out some results after each epoch\n","model.fit(X_train, Y_train, batch_size=8, epochs=20, verbose=1)"],"metadata":{"id":"qgg0nlaTrcmr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["score = model.evaluate(X_test, Y_test, verbose=0)\n","print('Test score:', score[0])\n","print('Test accuracy:', score[1])"],"metadata":{"id":"RtOuxNU5uAy1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now I will test the sigmoid activation function."],"metadata":{"id":"vhS3Hk19v1Km"}},{"cell_type":"code","source":["model = Sequential()\n","# our first dense layer\n","model.add(Dense(128, input_shape=(784,), activation=\"sigmoid\"))\n","# our second dense layer\n","model.add(Dense(64, activation=\"sigmoid\"))\n","# our third dense layer\n","model.add(Dense(64, activation=\"sigmoid\"))\n","# our fourth dense layer\n","model.add(Dense(32, activation=\"sigmoid\"))\n","# last layer is the output layer.\n","model.add(Dense(10, activation=\"softmax\"))\n","\n","model.compile(optimizer='sgd', loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","# setting verbose=1 prints out some results after each epoch\n","model.fit(X_train, Y_train, batch_size=8, epochs=20, verbose=1)"],"metadata":{"id":"4H7KSBe_uC6d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["score = model.evaluate(X_test, Y_test, verbose=0)\n","print('Test score:', score[0])\n","print('Test accuracy:', score[1])"],"metadata":{"id":"NQYlpytyv8oC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Activation Function Results\n","\n","Relu:\n","Test score: 0.3740180432796478\n","Test accuracy: 0.868399977684021\n","\n","tanh:\n","Test score: 0.32836252450942993\n","Test accuracy: 0.8852999806404114\n","\n","sigmoid:\n","Test score: 0.4549947679042816\n","Test accuracy: 0.8432999849319458\n","\n","tanh produces the highest test accuracy, so we will use this activation function moving forward.\n","\n","Next, I will test loss functions by changing from categorical crossentropy to categorical hinge."],"metadata":{"id":"Tfm5PFCuxG1M"}},{"cell_type":"code","source":["model = Sequential()\n","# our first dense layer\n","model.add(Dense(128, input_shape=(784,), activation=\"tanh\"))\n","# our second dense layer\n","model.add(Dense(64, activation=\"tanh\"))\n","# our third dense layer\n","model.add(Dense(64, activation=\"tanh\"))\n","# our fourth dense layer\n","model.add(Dense(32, activation=\"tanh\"))\n","# last layer is the output layer.\n","model.add(Dense(10, activation=\"softmax\"))\n","\n","model.compile(optimizer='sgd', loss='categorical_hinge',\n","              metrics=['accuracy'])\n","\n","# setting verbose=1 prints out some results after each epoch\n","model.fit(X_train, Y_train, batch_size=8, epochs=20, verbose=1)"],"metadata":{"id":"-4a41TYdxbw_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["score = model.evaluate(X_test, Y_test, verbose=0)\n","print('Test score:', score[0])\n","print('Test accuracy:', score[1])"],"metadata":{"id":"E7ZcE0lu4qC5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Activation Function Results\n","\n","Categorical Crossentropy: \n","Test score: 0.4549947679042816\n","Test accuracy: 0.8432999849319458\n","\n","Categorical Hinge:\n","Test score: 0.2602691352367401\n","Test accuracy: 0.8687999844551086\n","\n","Categorical Hinge produces the highest test accuracy, so we will use this activation function moving forward.\n","\n","Next, I will test the number of neurons in each non-output layer. Our working model is set to 128, 64, 64, 32. We will change this to double the value at each layer where we will us 256, 128, 128, 64.\n"],"metadata":{"id":"pjyUjXQ05-Rs"}},{"cell_type":"code","source":["model = Sequential()\n","# our first dense layer\n","model.add(Dense(256, input_shape=(784,), activation=\"tanh\"))\n","# our second dense layer\n","model.add(Dense(128, activation=\"tanh\"))\n","# our third dense layer\n","model.add(Dense(128, activation=\"tanh\"))\n","# our fourth dense layer\n","model.add(Dense(64, activation=\"tanh\"))\n","# last layer is the output layer.\n","model.add(Dense(10, activation=\"softmax\"))\n","\n","model.compile(optimizer='sgd', loss='categorical_hinge',\n","              metrics=['accuracy'])\n","\n","# setting verbose=1 prints out some results after each epoch\n","model.fit(X_train, Y_train, batch_size=8, epochs=20, verbose=1)"],"metadata":{"id":"LAeYw_WR4r3I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["score = model.evaluate(X_test, Y_test, verbose=0)\n","print('Test score:', score[0])\n","print('Test accuracy:', score[1])"],"metadata":{"id":"NlY6uUtD7UTO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Next, I will test the number of neurons in each non-output layer. Our working model is set to 128, 64, 32, 32. We will change this to half the value at each layer where we will us 64, 32, 16, 16."],"metadata":{"id":"060Th2zV8-GK"}},{"cell_type":"code","source":["model = Sequential()\n","# our first dense layer\n","model.add(Dense(64, input_shape=(784,), activation=\"tanh\"))\n","# our second dense layer\n","model.add(Dense(32, activation=\"tanh\"))\n","# our third dense layer\n","model.add(Dense(16, activation=\"tanh\"))\n","# our fourth dense layer\n","model.add(Dense(16, activation=\"tanh\"))\n","# last layer is the output layer.\n","model.add(Dense(10, activation=\"softmax\"))\n","\n","model.compile(optimizer='sgd', loss='categorical_hinge',\n","              metrics=['accuracy'])\n","\n","# setting verbose=1 prints out some results after each epoch\n","model.fit(X_train, Y_train, batch_size=8, epochs=20, verbose=1)"],"metadata":{"id":"nuWQWyfD7khk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["score = model.evaluate(X_test, Y_test, verbose=0)\n","print('Test score:', score[0])\n","print('Test accuracy:', score[1])"],"metadata":{"id":"OGIIufCB9k0h"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Layer Neuron Count Results\n","\n","Working model:\n","Test score: 0.2602691352367401\n","Test accuracy: 0.8687999844551086\n","\n","Double: \n","Test score: 0.2553660273551941\n","Test accuracy: 0.8720999956130981\n","\n","Half: \n","Test score: 0.2641873061656952\n","Test accuracy: 0.8673999905586243\n","\n","Doubling the number of neurons per layer produces the highest test accuracy, so we will use this number of neurons per layer moving forward.\n","\n","Next, I will test the batch size. Our working model is set to batch size = 8. We will test the effect of doubling and also halving that value.\n"],"metadata":{"id":"fnOwK8RM_AHf"}},{"cell_type":"code","source":["model = Sequential()\n","# our first dense layer\n","model.add(Dense(256, input_shape=(784,), activation=\"tanh\"))\n","# our second dense layer\n","model.add(Dense(128, activation=\"tanh\"))\n","# our third dense layer\n","model.add(Dense(128, activation=\"tanh\"))\n","# our fourth dense layer\n","model.add(Dense(64, activation=\"tanh\"))\n","# last layer is the output layer.\n","model.add(Dense(10, activation=\"softmax\"))\n","\n","model.compile(optimizer='sgd', loss='categorical_hinge',\n","              metrics=['accuracy'])\n","\n","# setting verbose=1 prints out some results after each epoch\n","model.fit(X_train, Y_train, batch_size=16, epochs=20, verbose=1)"],"metadata":{"id":"2ZlM6QFM9mZy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["score = model.evaluate(X_test, Y_test, verbose=0)\n","print('Test score:', score[0])\n","print('Test accuracy:', score[1])"],"metadata":{"id":"qy6WGuD6AJ5A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = Sequential()\n","# our first dense layer\n","model.add(Dense(256, input_shape=(784,), activation=\"tanh\"))\n","# our second dense layer\n","model.add(Dense(128, activation=\"tanh\"))\n","# our third dense layer\n","model.add(Dense(128, activation=\"tanh\"))\n","# our fourth dense layer\n","model.add(Dense(64, activation=\"tanh\"))\n","# last layer is the output layer.\n","model.add(Dense(10, activation=\"softmax\"))\n","\n","model.compile(optimizer='sgd', loss='categorical_hinge',\n","              metrics=['accuracy'])\n","\n","# setting verbose=1 prints out some results after each epoch\n","model.fit(X_train, Y_train, batch_size=4, epochs=20, verbose=1)"],"metadata":{"id":"kS_RvoizAMFI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["score = model.evaluate(X_test, Y_test, verbose=0)\n","print('Test score:', score[0])\n","print('Test accuracy:', score[1])"],"metadata":{"id":"wN6-XxCNAOQX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = Sequential()\n","# our first dense layer\n","model.add(Dense(256, input_shape=(784,), activation=\"tanh\"))\n","# our second dense layer\n","model.add(Dense(128, activation=\"tanh\"))\n","# our third dense layer\n","model.add(Dense(128, activation=\"tanh\"))\n","# our fourth dense layer\n","model.add(Dense(64, activation=\"tanh\"))\n","# last layer is the output layer.\n","model.add(Dense(10, activation=\"softmax\"))\n","\n","model.compile(optimizer='sgd', loss='categorical_hinge',\n","              metrics=['accuracy'])\n","\n","# setting verbose=1 prints out some results after each epoch\n","model.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jTOwHCFce9AX","executionInfo":{"status":"ok","timestamp":1654296903098,"user_tz":420,"elapsed":77617,"user":{"displayName":"Adam Astor","userId":"10506171213258147392"}},"outputId":"e0860290-a233-435a-c934-3e00ea965811"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","469/469 [==============================] - 5s 8ms/step - loss: 0.9208 - accuracy: 0.5073\n","Epoch 2/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.6893 - accuracy: 0.6769\n","Epoch 3/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.5895 - accuracy: 0.7266\n","Epoch 4/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.5118 - accuracy: 0.7832\n","Epoch 5/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.4474 - accuracy: 0.8070\n","Epoch 6/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.4092 - accuracy: 0.8178\n","Epoch 7/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.3846 - accuracy: 0.8264\n","Epoch 8/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.3675 - accuracy: 0.8317\n","Epoch 9/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.3552 - accuracy: 0.8361\n","Epoch 10/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.3449 - accuracy: 0.8391\n","Epoch 11/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.3369 - accuracy: 0.8415\n","Epoch 12/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.3300 - accuracy: 0.8439\n","Epoch 13/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.3239 - accuracy: 0.8468\n","Epoch 14/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.3186 - accuracy: 0.8488\n","Epoch 15/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.3133 - accuracy: 0.8513\n","Epoch 16/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.3091 - accuracy: 0.8528\n","Epoch 17/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.3054 - accuracy: 0.8539\n","Epoch 18/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.3013 - accuracy: 0.8563\n","Epoch 19/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.2982 - accuracy: 0.8578\n","Epoch 20/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.2952 - accuracy: 0.8591\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fca90574950>"]},"metadata":{},"execution_count":75}]},{"cell_type":"code","source":["score = model.evaluate(X_test, Y_test, verbose=0)\n","print('Test score:', score[0])\n","print('Test accuracy:', score[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1Hq9Q6Kke-mU","executionInfo":{"status":"ok","timestamp":1654296904107,"user_tz":420,"elapsed":1014,"user":{"displayName":"Adam Astor","userId":"10506171213258147392"}},"outputId":"5d8a11ab-35bf-4275-c368-02b5649c260d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test score: 0.3230695426464081\n","Test accuracy: 0.8417999744415283\n"]}]},{"cell_type":"code","source":["model = Sequential()\n","# our first dense layer\n","model.add(Dense(256, input_shape=(784,), activation=\"tanh\"))\n","# our second dense layer\n","model.add(Dense(128, activation=\"tanh\"))\n","# our third dense layer\n","model.add(Dense(128, activation=\"tanh\"))\n","# our fourth dense layer\n","model.add(Dense(64, activation=\"tanh\"))\n","# last layer is the output layer.\n","model.add(Dense(10, activation=\"softmax\"))\n","\n","model.compile(optimizer='sgd', loss='categorical_hinge',\n","              metrics=['accuracy'])\n","\n","# setting verbose=1 prints out some results after each epoch\n","model.fit(X_train, Y_train, batch_size=X_train.shape[0], epochs=20, verbose=1)"],"metadata":{"id":"bFeWOmFDgBML"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["score = model.evaluate(X_test, Y_test, verbose=0)\n","print('Test score:', score[0])\n","print('Test accuracy:', score[1])"],"metadata":{"id":"GnRCcFkwgChm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Batch Size Results\n","\n","Working model (8): \n","Test score: 0.2553660273551941\n","Test accuracy: 0.8720999956130981\n","\n","Double (16): \n","Test score: 0.25549373030662537\n","Test accuracy: 0.8737000226974487\n","\n","Half (4): \n","Test score: 0.25092509388923645\n","Test accuracy: 0.8741999864578247\n","\n","128:\n","Test score: 0.32467037439346313\n","Test accuracy: 0.8428999781608582\n","\n","Full sample (X_train.shape[0]):\n","Test score: 1.0527364015579224\n","Test accuracy: 0.10670000314712524\n","\n","The best performance in the training set is achieved using batch size 128 and in the test set using 4 as the mini batch size. However, the difference between the scores of the training and test sets are relatively large for all mini batch sizes. Since the scores achieved when using 128 as the mini batch size are close to those that are achieved when using 4 as the mini batch size, one can go with 128 because of the overfitting concerns. \n","\n","Next, I will test the number of epochs. Our working model is set to 20. We will test the effect of doubling and also having that value.\n"],"metadata":{"id":"WbHgizayEtIe"}},{"cell_type":"code","source":["model = Sequential()\n","# our first dense layer\n","model.add(Dense(256, input_shape=(784,), activation=\"tanh\"))\n","# our second dense layer\n","model.add(Dense(128, activation=\"tanh\"))\n","# our third dense layer\n","model.add(Dense(128, activation=\"tanh\"))\n","# our fourth dense layer\n","model.add(Dense(64, activation=\"tanh\"))\n","# last layer is the output layer.\n","model.add(Dense(10, activation=\"softmax\"))\n","\n","model.compile(optimizer='sgd', loss='categorical_hinge',\n","              metrics=['accuracy'])\n","\n","# setting verbose=1 prints out some results after each epoch\n","model.fit(X_train, Y_train, batch_size=128, epochs=40, verbose=1)"],"metadata":{"id":"calfnGjREs4G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["score = model.evaluate(X_test, Y_test, verbose=0)\n","print('Test score:', score[0])\n","print('Test accuracy:', score[1])"],"metadata":{"id":"ukBQoKgYAPba"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = Sequential()\n","# our first dense layer\n","model.add(Dense(256, input_shape=(784,), activation=\"tanh\"))\n","# our second dense layer\n","model.add(Dense(128, activation=\"tanh\"))\n","# our third dense layer\n","model.add(Dense(128, activation=\"tanh\"))\n","# our fourth dense layer\n","model.add(Dense(64, activation=\"tanh\"))\n","# last layer is the output layer.\n","model.add(Dense(10, activation=\"softmax\"))\n","\n","model.compile(optimizer='sgd', loss='categorical_hinge',\n","              metrics=['accuracy'])\n","\n","# setting verbose=1 prints out some results after each epoch\n","model.fit(X_train, Y_train, batch_size=128, epochs=10, verbose=1)"],"metadata":{"id":"nCyfQrk1GT3G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["score = model.evaluate(X_test, Y_test, verbose=0)\n","print('Test score:', score[0])\n","print('Test accuracy:', score[1])"],"metadata":{"id":"6dTVz2okGV3l"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Number of Epochs Results\n","\n","Working model (20):\n","Test score: 0.32467037439346313\n","Test accuracy: 0.8428999781608582\n","\n","Double (40): \n","Test score: 0.28890904784202576\n","Test accuracy: 0.8585000038146973\n","\n","Half (10): \n","Test score: 0.3629935383796692\n","Test accuracy: 0.828000009059906\n","\n","Doubling the number of epochs produces the highest test accuracy. Although, the increase in compute time is not worth the marginal increase in accuracy when compared tot he working model. We will accept the working model and move forward with 20 epochs\n","\n","Next, I will test the learning rate. Our working model is set to 1. We will test the effect of 100, 0.01 and 0.0000001 to compare to our working model.\n","\n"],"metadata":{"id":"1ezqLEpbGCOZ"}},{"cell_type":"code","source":["sgd_001 = optimizers.SGD(lr=0.01)\n","sgd_100 = optimizers.SGD(lr=100)\n","sgd_00000001 = optimizers.SGD(lr=0.0000001)"],"metadata":{"id":"ZHY_mn8ttoYH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = Sequential()\n","# our first dense layer\n","model.add(Dense(256, input_shape=(784,), activation=\"tanh\"))\n","# our second dense layer\n","model.add(Dense(128, activation=\"tanh\"))\n","# our third dense layer\n","model.add(Dense(128, activation=\"tanh\"))\n","# our fourth dense layer\n","model.add(Dense(64, activation=\"tanh\"))\n","# last layer is the output layer.\n","model.add(Dense(10, activation=\"softmax\"))\n","\n","model.compile(optimizer=sgd_100, loss='categorical_hinge',\n","              metrics=['accuracy'])\n","\n","# setting verbose=1 prints out some results after each epoch\n","model.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QufdqLPhF99Q","executionInfo":{"status":"ok","timestamp":1654295860909,"user_tz":420,"elapsed":65668,"user":{"displayName":"Adam Astor","userId":"10506171213258147392"}},"outputId":"e6cbe1f7-39c2-4486-be23-567b8343f7a0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","469/469 [==============================] - 4s 7ms/step - loss: 1.7976 - accuracy: 0.0998\n","Epoch 2/20\n","469/469 [==============================] - 4s 8ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 3/20\n","469/469 [==============================] - 3s 7ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 4/20\n","469/469 [==============================] - 3s 7ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 5/20\n","469/469 [==============================] - 3s 7ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 6/20\n","469/469 [==============================] - 3s 7ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 7/20\n","469/469 [==============================] - 3s 7ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 8/20\n","469/469 [==============================] - 3s 7ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 9/20\n","469/469 [==============================] - 3s 7ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 10/20\n","469/469 [==============================] - 3s 7ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 11/20\n","469/469 [==============================] - 3s 7ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 12/20\n","469/469 [==============================] - 3s 7ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 13/20\n","469/469 [==============================] - 3s 7ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 14/20\n","469/469 [==============================] - 3s 7ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 15/20\n","469/469 [==============================] - 3s 7ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 16/20\n","469/469 [==============================] - 3s 7ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 17/20\n","469/469 [==============================] - 3s 7ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 18/20\n","469/469 [==============================] - 3s 7ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 19/20\n","469/469 [==============================] - 4s 9ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 20/20\n","469/469 [==============================] - 3s 7ms/step - loss: 1.8000 - accuracy: 0.1000\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fca9da00750>"]},"metadata":{},"execution_count":69}]},{"cell_type":"code","source":["score = model.evaluate(X_test, Y_test, verbose=0)\n","print('Test score:', score[0])\n","print('Test accuracy:', score[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mjV_jQw2tDFb","executionInfo":{"status":"ok","timestamp":1654295861375,"user_tz":420,"elapsed":469,"user":{"displayName":"Adam Astor","userId":"10506171213258147392"}},"outputId":"c69bd352-5f03-46a5-8017-2b05dda0a467"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test score: 1.7999999523162842\n","Test accuracy: 0.10000000149011612\n"]}]},{"cell_type":"code","source":["model = Sequential()\n","# our first dense layer\n","model.add(Dense(256, input_shape=(784,), activation=\"tanh\"))\n","# our second dense layer\n","model.add(Dense(128, activation=\"tanh\"))\n","# our third dense layer\n","model.add(Dense(128, activation=\"tanh\"))\n","# our fourth dense layer\n","model.add(Dense(64, activation=\"tanh\"))\n","# last layer is the output layer.\n","model.add(Dense(10, activation=\"softmax\"))\n","\n","model.compile(optimizer=sgd_001, loss='categorical_hinge',\n","              metrics=['accuracy'])\n","\n","# setting verbose=1 prints out some results after each epoch\n","model.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0SpUqsTRtNsA","executionInfo":{"status":"ok","timestamp":1654295945270,"user_tz":420,"elapsed":82684,"user":{"displayName":"Adam Astor","userId":"10506171213258147392"}},"outputId":"aedfcd65-72e5-475e-9d40-23ff5226e7bc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.9398 - accuracy: 0.4544\n","Epoch 2/20\n","469/469 [==============================] - 3s 7ms/step - loss: 0.7150 - accuracy: 0.6832\n","Epoch 3/20\n","469/469 [==============================] - 3s 7ms/step - loss: 0.5673 - accuracy: 0.7607\n","Epoch 4/20\n","469/469 [==============================] - 3s 7ms/step - loss: 0.5000 - accuracy: 0.7883\n","Epoch 5/20\n","469/469 [==============================] - 3s 7ms/step - loss: 0.4511 - accuracy: 0.8046\n","Epoch 6/20\n","469/469 [==============================] - 3s 7ms/step - loss: 0.4144 - accuracy: 0.8157\n","Epoch 7/20\n","469/469 [==============================] - 3s 7ms/step - loss: 0.3893 - accuracy: 0.8233\n","Epoch 8/20\n","469/469 [==============================] - 3s 7ms/step - loss: 0.3718 - accuracy: 0.8292\n","Epoch 9/20\n","469/469 [==============================] - 3s 7ms/step - loss: 0.3584 - accuracy: 0.8352\n","Epoch 10/20\n","469/469 [==============================] - 3s 7ms/step - loss: 0.3480 - accuracy: 0.8389\n","Epoch 11/20\n","469/469 [==============================] - 3s 7ms/step - loss: 0.3390 - accuracy: 0.8432\n","Epoch 12/20\n","469/469 [==============================] - 3s 7ms/step - loss: 0.3316 - accuracy: 0.8461\n","Epoch 13/20\n","469/469 [==============================] - 3s 7ms/step - loss: 0.3252 - accuracy: 0.8478\n","Epoch 14/20\n","469/469 [==============================] - 3s 7ms/step - loss: 0.3196 - accuracy: 0.8504\n","Epoch 15/20\n","469/469 [==============================] - 3s 7ms/step - loss: 0.3144 - accuracy: 0.8517\n","Epoch 16/20\n","469/469 [==============================] - 3s 7ms/step - loss: 0.3095 - accuracy: 0.8536\n","Epoch 17/20\n","469/469 [==============================] - 3s 7ms/step - loss: 0.3056 - accuracy: 0.8559\n","Epoch 18/20\n","469/469 [==============================] - 3s 7ms/step - loss: 0.3013 - accuracy: 0.8571\n","Epoch 19/20\n","469/469 [==============================] - 3s 7ms/step - loss: 0.2977 - accuracy: 0.8592\n","Epoch 20/20\n","469/469 [==============================] - 3s 7ms/step - loss: 0.2946 - accuracy: 0.8602\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fca9083fb10>"]},"metadata":{},"execution_count":71}]},{"cell_type":"code","source":["score = model.evaluate(X_test, Y_test, verbose=0)\n","print('Test score:', score[0])\n","print('Test accuracy:', score[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f35qqnCNt4Ms","executionInfo":{"status":"ok","timestamp":1654295945819,"user_tz":420,"elapsed":553,"user":{"displayName":"Adam Astor","userId":"10506171213258147392"}},"outputId":"fe5fc174-7a54-4359-cf67-de9ff2c62e87"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test score: 0.3223553001880646\n","Test accuracy: 0.8416000008583069\n"]}]},{"cell_type":"code","source":["model = Sequential()\n","# our first dense layer\n","model.add(Dense(256, input_shape=(784,), activation=\"tanh\"))\n","# our second dense layer\n","model.add(Dense(128, activation=\"tanh\"))\n","# our third dense layer\n","model.add(Dense(128, activation=\"tanh\"))\n","# our fourth dense layer\n","model.add(Dense(64, activation=\"tanh\"))\n","# last layer is the output layer.\n","model.add(Dense(10, activation=\"softmax\"))\n","\n","model.compile(optimizer=sgd_00000001, loss='categorical_hinge',\n","              metrics=['accuracy'])\n","\n","# setting verbose=1 prints out some results after each epoch\n","model.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZWOIaqvwt6v0","executionInfo":{"status":"ok","timestamp":1654296016533,"user_tz":420,"elapsed":70717,"user":{"displayName":"Adam Astor","userId":"10506171213258147392"}},"outputId":"f398d3e8-973f-42eb-94c5-cfb38d1ff096"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","469/469 [==============================] - 4s 7ms/step - loss: 1.0652 - accuracy: 0.0836\n","Epoch 2/20\n","469/469 [==============================] - 3s 7ms/step - loss: 1.0652 - accuracy: 0.0836\n","Epoch 3/20\n","469/469 [==============================] - 3s 7ms/step - loss: 1.0652 - accuracy: 0.0836\n","Epoch 4/20\n","469/469 [==============================] - 3s 7ms/step - loss: 1.0652 - accuracy: 0.0836\n","Epoch 5/20\n","469/469 [==============================] - 3s 7ms/step - loss: 1.0652 - accuracy: 0.0836\n","Epoch 6/20\n","469/469 [==============================] - 3s 7ms/step - loss: 1.0652 - accuracy: 0.0836\n","Epoch 7/20\n","469/469 [==============================] - 4s 9ms/step - loss: 1.0652 - accuracy: 0.0836\n","Epoch 8/20\n","469/469 [==============================] - 3s 7ms/step - loss: 1.0652 - accuracy: 0.0836\n","Epoch 9/20\n","469/469 [==============================] - 3s 7ms/step - loss: 1.0652 - accuracy: 0.0836\n","Epoch 10/20\n","469/469 [==============================] - 3s 7ms/step - loss: 1.0652 - accuracy: 0.0836\n","Epoch 11/20\n","469/469 [==============================] - 3s 7ms/step - loss: 1.0652 - accuracy: 0.0836\n","Epoch 12/20\n","469/469 [==============================] - 3s 7ms/step - loss: 1.0652 - accuracy: 0.0836\n","Epoch 13/20\n","469/469 [==============================] - 4s 8ms/step - loss: 1.0652 - accuracy: 0.0836\n","Epoch 14/20\n","469/469 [==============================] - 4s 8ms/step - loss: 1.0652 - accuracy: 0.0835\n","Epoch 15/20\n","469/469 [==============================] - 4s 8ms/step - loss: 1.0652 - accuracy: 0.0835\n","Epoch 16/20\n","469/469 [==============================] - 4s 8ms/step - loss: 1.0652 - accuracy: 0.0835\n","Epoch 17/20\n","469/469 [==============================] - 4s 8ms/step - loss: 1.0652 - accuracy: 0.0835\n","Epoch 18/20\n","469/469 [==============================] - 4s 8ms/step - loss: 1.0652 - accuracy: 0.0835\n","Epoch 19/20\n","469/469 [==============================] - 4s 8ms/step - loss: 1.0652 - accuracy: 0.0835\n","Epoch 20/20\n","469/469 [==============================] - 4s 8ms/step - loss: 1.0652 - accuracy: 0.0835\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fca906c15d0>"]},"metadata":{},"execution_count":73}]},{"cell_type":"code","source":["score = model.evaluate(X_test, Y_test, verbose=0)\n","print('Test score:', score[0])\n","print('Test accuracy:', score[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KoGS_3IfuGdq","executionInfo":{"status":"ok","timestamp":1654296017147,"user_tz":420,"elapsed":620,"user":{"displayName":"Adam Astor","userId":"10506171213258147392"}},"outputId":"74194f85-9ca1-4675-b9b1-cfb74ff34109"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test score: 1.0660972595214844\n","Test accuracy: 0.08219999819993973\n"]}]},{"cell_type":"markdown","source":["Learning Rate: 100\n","Test score: 1.7999999523162842\n","Test accuracy: 0.10000000149011612\n","\n","Working model (Learning Rate: 0.01)\n","Test score: 0.3230695426464081\n","Test accuracy: 0.8417999744415283\n","\n","Learning Rate: 0.01\n","Test score: 0.3223553001880646\n","Test accuracy: 0.8416000008583069\n","\n","Learning Rate: 0.0000001\n","Test score: 1.0660972595214844\n","Test accuracy: 0.08219999819993973\n","\n","From these results I can see that when the learning rate is set to 100, accuracy is at it's highest at 0.100. However, this is too accurate and will produce overfitting. We will try setting the learning rate to values between 1 and 100 to try to find an accuracy that is near 0.95."],"metadata":{"id":"t2PsREFCwTRN"}},{"cell_type":"code","source":["sgd_25 = optimizers.SGD(lr=25)\n","sgd_50 = optimizers.SGD(lr=50)\n","sgd_75 = optimizers.SGD(lr=75)"],"metadata":{"id":"Tc9mLjVnuICS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = Sequential()\n","# our first dense layer\n","model.add(Dense(256, input_shape=(784,), activation=\"tanh\"))\n","# our second dense layer\n","model.add(Dense(128, activation=\"tanh\"))\n","# our third dense layer\n","model.add(Dense(128, activation=\"tanh\"))\n","# our fourth dense layer\n","model.add(Dense(64, activation=\"tanh\"))\n","# last layer is the output layer.\n","model.add(Dense(10, activation=\"softmax\"))\n","\n","model.compile(optimizer=sgd_25, loss='categorical_hinge',\n","              metrics=['accuracy'])\n","\n","# setting verbose=1 prints out some results after each epoch\n","model.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VYL25OM543Wy","executionInfo":{"status":"ok","timestamp":1654450992799,"user_tz":420,"elapsed":54541,"user":{"displayName":"Adam Astor","userId":"10506171213258147392"}},"outputId":"ef2252bc-cc2f-4295-bc11-5492bde96ba6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.7974 - accuracy: 0.1001\n","Epoch 2/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 3/20\n","469/469 [==============================] - 3s 5ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 4/20\n","469/469 [==============================] - 3s 5ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 5/20\n","469/469 [==============================] - 3s 5ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 6/20\n","469/469 [==============================] - 2s 5ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 7/20\n","469/469 [==============================] - 3s 5ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 8/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 9/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 10/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 11/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 12/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 13/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 14/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 15/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 16/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 17/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 18/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 19/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 20/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f86db1803d0>"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["score = model.evaluate(X_test, Y_test, verbose=0)\n","print('Test score:', score[0])\n","print('Test accuracy:', score[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uDXNjiWe5B8o","executionInfo":{"status":"ok","timestamp":1654450993688,"user_tz":420,"elapsed":892,"user":{"displayName":"Adam Astor","userId":"10506171213258147392"}},"outputId":"d35ec977-1713-4d21-bf6c-d2627f2f8441"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test score: 1.7999999523162842\n","Test accuracy: 0.10000000149011612\n"]}]},{"cell_type":"code","source":["model = Sequential()\n","# our first dense layer\n","model.add(Dense(256, input_shape=(784,), activation=\"tanh\"))\n","# our second dense layer\n","model.add(Dense(128, activation=\"tanh\"))\n","# our third dense layer\n","model.add(Dense(128, activation=\"tanh\"))\n","# our fourth dense layer\n","model.add(Dense(64, activation=\"tanh\"))\n","# last layer is the output layer.\n","model.add(Dense(10, activation=\"softmax\"))\n","\n","model.compile(optimizer=sgd_50, loss='categorical_hinge',\n","              metrics=['accuracy'])\n","\n","# setting verbose=1 prints out some results after each epoch\n","model.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":487},"id":"B_OsR51448nW","executionInfo":{"status":"error","timestamp":1654451002423,"user_tz":420,"elapsed":8737,"user":{"displayName":"Adam Astor","userId":"10506171213258147392"}},"outputId":"07cac18b-d976-44e4-9e06-65dd42e75bc3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","469/469 [==============================] - 4s 6ms/step - loss: 1.7975 - accuracy: 0.0999\n","Epoch 2/20\n","469/469 [==============================] - 3s 5ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 3/20\n","402/469 [========================>.....] - ETA: 0s - loss: 1.8010 - accuracy: 0.0995"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-91b1b2d5e88c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# setting verbose=1 prints out some results after each epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["score = model.evaluate(X_test, Y_test, verbose=0)\n","print('Test score:', score[0])\n","print('Test accuracy:', score[1])"],"metadata":{"id":"rszs3xE65DZS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = Sequential()\n","# our first dense layer\n","model.add(Dense(256, input_shape=(784,), activation=\"tanh\"))\n","# our second dense layer\n","model.add(Dense(128, activation=\"tanh\"))\n","# our third dense layer\n","model.add(Dense(128, activation=\"tanh\"))\n","# our fourth dense layer\n","model.add(Dense(64, activation=\"tanh\"))\n","# last layer is the output layer.\n","model.add(Dense(10, activation=\"softmax\"))\n","\n","model.compile(optimizer=sgd_75, loss='categorical_hinge',\n","              metrics=['accuracy'])\n","\n","# setting verbose=1 prints out some results after each epoch\n","model.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=1)"],"metadata":{"id":"TU9ao1FL4-1K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["score = model.evaluate(X_test, Y_test, verbose=0)\n","print('Test score:', score[0])\n","print('Test accuracy:', score[1])"],"metadata":{"id":"QaLT8cS-5FAH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Learning Rate: 100\n","Test score: 1.7999999523162842\n","Test accuracy: 0.10000000149011612\n","\n","Learning Rate: 75\n","Test score: 1.7999999523162842\n","Test accuracy: 0.10000000149011612\n","\n","Learning Rate: 50\n","Test score: 1.7999999523162842\n","Test accuracy: 0.10000000149011612\n","\n","Learning Rate: 25\n","Test score: 1.7999999523162842\n","Test accuracy: 0.10000000149011612\n","\n","Working model (Learning Rate: 0.01)\n","Test score: 0.3230695426464081\n","Test accuracy: 0.8417999744415283\n","\n","The working model is stil the only valid learning rate amongst these results. We will search again for a higher performing value for learning rate with values at 2, 5, and 7."],"metadata":{"id":"1-9hSqSa5N9K"}},{"cell_type":"code","source":["sgd_2 = optimizers.SGD(lr=2)\n","sgd_5 = optimizers.SGD(lr=5)\n","sgd_7 = optimizers.SGD(lr=7)"],"metadata":{"id":"lXGNb8kH5F2G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = Sequential()\n","# our first dense layer\n","model.add(Dense(256, input_shape=(784,), activation=\"tanh\"))\n","# our second dense layer\n","model.add(Dense(128, activation=\"tanh\"))\n","# our third dense layer\n","model.add(Dense(128, activation=\"tanh\"))\n","# our fourth dense layer\n","model.add(Dense(64, activation=\"tanh\"))\n","# last layer is the output layer.\n","model.add(Dense(10, activation=\"softmax\"))\n","\n","model.compile(optimizer=sgd_2, loss='categorical_hinge',\n","              metrics=['accuracy'])\n","\n","# setting verbose=1 prints out some results after each epoch\n","model.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8XmrpQW-9sEJ","executionInfo":{"status":"ok","timestamp":1654451116671,"user_tz":420,"elapsed":55740,"user":{"displayName":"Adam Astor","userId":"10506171213258147392"}},"outputId":"30fb2bf1-2b2c-444a-abd4-80e49c612885"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.7943 - accuracy: 0.0997\n","Epoch 2/20\n","469/469 [==============================] - 3s 5ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 3/20\n","469/469 [==============================] - 3s 5ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 4/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 5/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 6/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 7/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 8/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 9/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 10/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 11/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 12/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 13/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 14/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 15/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 16/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 17/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 18/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 19/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 20/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f86dad08510>"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["score = model.evaluate(X_test, Y_test, verbose=0)\n","print('Test score:', score[0])\n","print('Test accuracy:', score[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zDLcREAo9zOV","executionInfo":{"status":"ok","timestamp":1654451117522,"user_tz":420,"elapsed":855,"user":{"displayName":"Adam Astor","userId":"10506171213258147392"}},"outputId":"cd9c1531-d3c1-4838-dfda-4d39360f857f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test score: 1.7999999523162842\n","Test accuracy: 0.10000000149011612\n"]}]},{"cell_type":"code","source":["model = Sequential()\n","# our first dense layer\n","model.add(Dense(256, input_shape=(784,), activation=\"tanh\"))\n","# our second dense layer\n","model.add(Dense(128, activation=\"tanh\"))\n","# our third dense layer\n","model.add(Dense(128, activation=\"tanh\"))\n","# our fourth dense layer\n","model.add(Dense(64, activation=\"tanh\"))\n","# last layer is the output layer.\n","model.add(Dense(10, activation=\"softmax\"))\n","\n","model.compile(optimizer=sgd_5, loss='categorical_hinge',\n","              metrics=['accuracy'])\n","\n","# setting verbose=1 prints out some results after each epoch\n","model.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"32UY5lw89wuF","executionInfo":{"status":"ok","timestamp":1654451171467,"user_tz":420,"elapsed":53949,"user":{"displayName":"Adam Astor","userId":"10506171213258147392"}},"outputId":"6c12b6b6-4c15-488d-a6a7-c3d42c4845e9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.7952 - accuracy: 0.1002\n","Epoch 2/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 3/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 4/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 5/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 6/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 7/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 8/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 9/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 10/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 11/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 12/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 13/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 14/20\n","469/469 [==============================] - 3s 5ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 15/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 16/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 17/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 18/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 19/20\n","469/469 [==============================] - 3s 5ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 20/20\n","469/469 [==============================] - 3s 5ms/step - loss: 1.8000 - accuracy: 0.1000\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f86dab32d10>"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["score = model.evaluate(X_test, Y_test, verbose=0)\n","print('Test score:', score[0])\n","print('Test accuracy:', score[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EXIhv9Uh90Dy","executionInfo":{"status":"ok","timestamp":1654451172173,"user_tz":420,"elapsed":711,"user":{"displayName":"Adam Astor","userId":"10506171213258147392"}},"outputId":"4e9c883d-8c03-4611-e2fb-ad9c046c0b9e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test score: 1.7999999523162842\n","Test accuracy: 0.10000000149011612\n"]}]},{"cell_type":"code","source":["model = Sequential()\n","# our first dense layer\n","model.add(Dense(256, input_shape=(784,), activation=\"tanh\"))\n","# our second dense layer\n","model.add(Dense(128, activation=\"tanh\"))\n","# our third dense layer\n","model.add(Dense(128, activation=\"tanh\"))\n","# our fourth dense layer\n","model.add(Dense(64, activation=\"tanh\"))\n","# last layer is the output layer.\n","model.add(Dense(10, activation=\"softmax\"))\n","\n","model.compile(optimizer=sgd_7, loss='categorical_hinge',\n","              metrics=['accuracy'])\n","\n","# setting verbose=1 prints out some results after each epoch\n","model.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2AZ6UeAL9xTo","executionInfo":{"status":"ok","timestamp":1654451224681,"user_tz":420,"elapsed":52352,"user":{"displayName":"Adam Astor","userId":"10506171213258147392"}},"outputId":"fd8bbcac-69a3-42ac-8895-ef2ceca17595"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.7960 - accuracy: 0.1000\n","Epoch 2/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 3/20\n","469/469 [==============================] - 3s 5ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 4/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 5/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 6/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 7/20\n","469/469 [==============================] - 3s 5ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 8/20\n","469/469 [==============================] - 3s 5ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 9/20\n","469/469 [==============================] - 3s 5ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 10/20\n","469/469 [==============================] - 3s 5ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 11/20\n","469/469 [==============================] - 3s 5ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 12/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 13/20\n","469/469 [==============================] - 3s 5ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 14/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 15/20\n","469/469 [==============================] - 3s 5ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 16/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 17/20\n","469/469 [==============================] - 3s 5ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 18/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 19/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 20/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f86da9c8f90>"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["score = model.evaluate(X_test, Y_test, verbose=0)\n","print('Test score:', score[0])\n","print('Test accuracy:', score[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MTL9aUDw90rL","executionInfo":{"status":"ok","timestamp":1654451225375,"user_tz":420,"elapsed":698,"user":{"displayName":"Adam Astor","userId":"10506171213258147392"}},"outputId":"ea4392c9-c448-41b6-d823-76b6f29c437c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test score: 1.7999999523162842\n","Test accuracy: 0.10000000149011612\n"]}]},{"cell_type":"markdown","source":["Learning Rate: 7\n","Test score: 1.7999999523162842\n","Test accuracy: 0.10000000149011612\n","\n","Learning Rate: 5\n","Test score: 1.7999999523162842\n","Test accuracy: 0.10000000149011612\n","\n","Learning Rate: 2\n","Test score: 1.7999999523162842\n","Test accuracy: 0.10000000149011612\n","\n","Working model (Learning Rate: 0.01)\n","Test score: 0.3230695426464081\n","Test accuracy: 0.8417999744415283\n","\n","The working model is stil the only valid learning rate amongst these results. We will search again for a higher performing value for learning rate with values at 1, 0.5, and 0.1."],"metadata":{"id":"VIiy2UE1_dFK"}},{"cell_type":"code","source":["sgd_1 = optimizers.SGD(lr=1)\n","sgd_05 = optimizers.SGD(lr=0.5)\n","sgd_01 = optimizers.SGD(lr=0.1)"],"metadata":{"id":"TGea_GBJ98kA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = Sequential()\n","# our first dense layer\n","model.add(Dense(256, input_shape=(784,), activation=\"tanh\"))\n","# our second dense layer\n","model.add(Dense(128, activation=\"tanh\"))\n","# our third dense layer\n","model.add(Dense(128, activation=\"tanh\"))\n","# our fourth dense layer\n","model.add(Dense(64, activation=\"tanh\"))\n","# last layer is the output layer.\n","model.add(Dense(10, activation=\"softmax\"))\n","\n","model.compile(optimizer=sgd_1, loss='categorical_hinge',\n","              metrics=['accuracy'])\n","\n","# setting verbose=1 prints out some results after each epoch\n","model.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"78Y0IuvSAUXV","executionInfo":{"status":"ok","timestamp":1654451787127,"user_tz":420,"elapsed":51356,"user":{"displayName":"Adam Astor","userId":"10506171213258147392"}},"outputId":"0e2eb161-2fb8-48c9-fe9e-0bb4040bbf6c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.7908 - accuracy: 0.1010\n","Epoch 2/20\n","469/469 [==============================] - 3s 5ms/step - loss: 1.7943 - accuracy: 0.1003\n","Epoch 3/20\n","469/469 [==============================] - 2s 5ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 4/20\n","469/469 [==============================] - 3s 5ms/step - loss: 1.7946 - accuracy: 0.1022\n","Epoch 5/20\n","469/469 [==============================] - 3s 5ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 6/20\n","469/469 [==============================] - 2s 5ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 7/20\n","469/469 [==============================] - 2s 5ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 8/20\n","469/469 [==============================] - 2s 5ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 9/20\n","469/469 [==============================] - 3s 5ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 10/20\n","469/469 [==============================] - 3s 5ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 11/20\n","469/469 [==============================] - 3s 5ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 12/20\n","469/469 [==============================] - 2s 5ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 13/20\n","469/469 [==============================] - 2s 5ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 14/20\n","469/469 [==============================] - 2s 5ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 15/20\n","469/469 [==============================] - 2s 5ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 16/20\n","469/469 [==============================] - 2s 5ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 17/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 18/20\n","469/469 [==============================] - 3s 5ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 19/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 20/20\n","469/469 [==============================] - 3s 5ms/step - loss: 1.8000 - accuracy: 0.1000\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f86da878810>"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["score = model.evaluate(X_test, Y_test, verbose=0)\n","print('Test score:', score[0])\n","print('Test accuracy:', score[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TqQ-89gpAeeE","executionInfo":{"status":"ok","timestamp":1654451787806,"user_tz":420,"elapsed":684,"user":{"displayName":"Adam Astor","userId":"10506171213258147392"}},"outputId":"a40a2e46-b3b1-4c89-8a2a-d6f3f7a2b23b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test score: 1.7999998331069946\n","Test accuracy: 0.10000000149011612\n"]}]},{"cell_type":"code","source":["model = Sequential()\n","# our first dense layer\n","model.add(Dense(256, input_shape=(784,), activation=\"tanh\"))\n","# our second dense layer\n","model.add(Dense(128, activation=\"tanh\"))\n","# our third dense layer\n","model.add(Dense(128, activation=\"tanh\"))\n","# our fourth dense layer\n","model.add(Dense(64, activation=\"tanh\"))\n","# last layer is the output layer.\n","model.add(Dense(10, activation=\"softmax\"))\n","\n","model.compile(optimizer=sgd_05, loss='categorical_hinge',\n","              metrics=['accuracy'])\n","\n","# setting verbose=1 prints out some results after each epoch\n","model.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"297TMH3cAZ5A","executionInfo":{"status":"ok","timestamp":1654629367242,"user_tz":420,"elapsed":83160,"user":{"displayName":"Adam Astor","userId":"10506171213258147392"}},"outputId":"22b4e9fa-d4df-4af6-ef2a-9ad61d63465c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","469/469 [==============================] - 4s 7ms/step - loss: 0.6563 - accuracy: 0.6490\n","Epoch 2/20\n","469/469 [==============================] - 3s 6ms/step - loss: 0.3719 - accuracy: 0.8127\n","Epoch 3/20\n","469/469 [==============================] - 3s 6ms/step - loss: 0.3346 - accuracy: 0.8310\n","Epoch 4/20\n","469/469 [==============================] - 3s 7ms/step - loss: 0.3148 - accuracy: 0.8418\n","Epoch 5/20\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2997 - accuracy: 0.8502\n","Epoch 6/20\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2871 - accuracy: 0.8558\n","Epoch 7/20\n","469/469 [==============================] - 3s 7ms/step - loss: 0.2822 - accuracy: 0.8584\n","Epoch 8/20\n","469/469 [==============================] - 3s 7ms/step - loss: 0.2738 - accuracy: 0.8628\n","Epoch 9/20\n","469/469 [==============================] - 3s 7ms/step - loss: 0.2671 - accuracy: 0.8659\n","Epoch 10/20\n","469/469 [==============================] - 3s 7ms/step - loss: 0.2618 - accuracy: 0.8685\n","Epoch 11/20\n","469/469 [==============================] - 3s 7ms/step - loss: 0.2563 - accuracy: 0.8712\n","Epoch 12/20\n","469/469 [==============================] - 3s 7ms/step - loss: 0.2550 - accuracy: 0.8718\n","Epoch 13/20\n","469/469 [==============================] - 3s 7ms/step - loss: 0.2513 - accuracy: 0.8739\n","Epoch 14/20\n","469/469 [==============================] - 3s 7ms/step - loss: 0.2469 - accuracy: 0.8760\n","Epoch 15/20\n","469/469 [==============================] - 3s 7ms/step - loss: 0.2463 - accuracy: 0.8767\n","Epoch 16/20\n","469/469 [==============================] - 3s 7ms/step - loss: 0.2409 - accuracy: 0.8790\n","Epoch 17/20\n","469/469 [==============================] - 3s 7ms/step - loss: 0.2356 - accuracy: 0.8821\n","Epoch 18/20\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2360 - accuracy: 0.8815\n","Epoch 19/20\n","469/469 [==============================] - 3s 7ms/step - loss: 0.2347 - accuracy: 0.8824\n","Epoch 20/20\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2290 - accuracy: 0.8853\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fe6d6ae5d50>"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["score = model.evaluate(X_test, Y_test, verbose=0)\n","print('Test score:', score[0])\n","print('Test accuracy:', score[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t1y-oecRAfGy","executionInfo":{"status":"ok","timestamp":1654629367654,"user_tz":420,"elapsed":416,"user":{"displayName":"Adam Astor","userId":"10506171213258147392"}},"outputId":"a1914508-1f1c-425c-d8ad-068a5a9d47ad"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test score: 0.2640962302684784\n","Test accuracy: 0.8672000169754028\n"]}]},{"cell_type":"code","source":["model = Sequential()\n","# our first dense layer\n","model.add(Dense(256, input_shape=(784,), activation=\"tanh\"))\n","# our second dense layer\n","model.add(Dense(128, activation=\"tanh\"))\n","# our third dense layer\n","model.add(Dense(128, activation=\"tanh\"))\n","# our fourth dense layer\n","model.add(Dense(64, activation=\"tanh\"))\n","# last layer is the output layer.\n","model.add(Dense(10, activation=\"softmax\"))\n","\n","model.compile(optimizer=sgd_01, loss='categorical_hinge',\n","              metrics=['accuracy'])\n","\n","# setting verbose=1 prints out some results after each epoch\n","model.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pOKw6HfTAanm","executionInfo":{"status":"ok","timestamp":1654451953680,"user_tz":420,"elapsed":82589,"user":{"displayName":"Adam Astor","userId":"10506171213258147392"}},"outputId":"a63562df-7628-48c2-ba27-26b67d2786a3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","469/469 [==============================] - 3s 5ms/step - loss: 0.5323 - accuracy: 0.7457\n","Epoch 2/20\n","469/469 [==============================] - 3s 5ms/step - loss: 0.3546 - accuracy: 0.8275\n","Epoch 3/20\n","469/469 [==============================] - 3s 5ms/step - loss: 0.3263 - accuracy: 0.8398\n","Epoch 4/20\n","469/469 [==============================] - 3s 5ms/step - loss: 0.3095 - accuracy: 0.8475\n","Epoch 5/20\n","469/469 [==============================] - 2s 5ms/step - loss: 0.2954 - accuracy: 0.8543\n","Epoch 6/20\n","469/469 [==============================] - 3s 5ms/step - loss: 0.2865 - accuracy: 0.8587\n","Epoch 7/20\n","469/469 [==============================] - 3s 5ms/step - loss: 0.2793 - accuracy: 0.8622\n","Epoch 8/20\n","469/469 [==============================] - 3s 5ms/step - loss: 0.2724 - accuracy: 0.8658\n","Epoch 9/20\n","469/469 [==============================] - 3s 5ms/step - loss: 0.2638 - accuracy: 0.8694\n","Epoch 10/20\n","469/469 [==============================] - 2s 5ms/step - loss: 0.2580 - accuracy: 0.8719\n","Epoch 11/20\n","469/469 [==============================] - 2s 5ms/step - loss: 0.2534 - accuracy: 0.8753\n","Epoch 12/20\n","469/469 [==============================] - 3s 5ms/step - loss: 0.2486 - accuracy: 0.8768\n","Epoch 13/20\n","469/469 [==============================] - 2s 5ms/step - loss: 0.2466 - accuracy: 0.8775\n","Epoch 14/20\n","469/469 [==============================] - 2s 5ms/step - loss: 0.2382 - accuracy: 0.8824\n","Epoch 15/20\n","469/469 [==============================] - 3s 5ms/step - loss: 0.2353 - accuracy: 0.8842\n","Epoch 16/20\n","469/469 [==============================] - 2s 5ms/step - loss: 0.2298 - accuracy: 0.8867\n","Epoch 17/20\n","469/469 [==============================] - 3s 5ms/step - loss: 0.2288 - accuracy: 0.8867\n","Epoch 18/20\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2251 - accuracy: 0.8890\n","Epoch 19/20\n","469/469 [==============================] - 3s 5ms/step - loss: 0.2212 - accuracy: 0.8908\n","Epoch 20/20\n","469/469 [==============================] - 3s 5ms/step - loss: 0.2176 - accuracy: 0.8927\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f86d0daced0>"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["score = model.evaluate(X_test, Y_test, verbose=0)\n","print('Test score:', score[0])\n","print('Test accuracy:', score[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CRLplqSEAfoB","executionInfo":{"status":"ok","timestamp":1654451954192,"user_tz":420,"elapsed":517,"user":{"displayName":"Adam Astor","userId":"10506171213258147392"}},"outputId":"6ccfa499-d387-4564-9a28-77e6d01cec7c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test score: 0.2883323132991791\n","Test accuracy: 0.8567000031471252\n"]}]},{"cell_type":"markdown","source":["Learning Rate: 1\n","Test score: 1.7999998331069946\n","Test accuracy: 0.10000000149011612\n","\n","Learning Rate: 0.5\n","Test score: 0.27018558979034424\n","Test accuracy: 0.864300012588501\n","\n","Learning Rate: 0.1\n","Test score: 0.2883323132991791\n","Test accuracy: 0.8567000031471252\n","\n","Working model (Learning Rate: 0.01)\n","Test score: 0.3230695426464081\n","Test accuracy: 0.8417999744415283\n","\n","We will accept a learning rate of 0.5 as the most successful value moving forward. Let's continue to test learning rate values between 0.5 and 1 for any further improvement. We will use values 0.6, 0.7, and 0.8."],"metadata":{"id":"wnwQ8Y20BhA6"}},{"cell_type":"code","source":["sgd_06 = optimizers.SGD(lr=0.6)\n","sgd_07 = optimizers.SGD(lr=0.7)\n","sgd_08 = optimizers.SGD(lr=0.8)"],"metadata":{"id":"9UIGKCcJAhKV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = Sequential()\n","# our first dense layer\n","model.add(Dense(256, input_shape=(784,), activation=\"tanh\"))\n","# our second dense layer\n","model.add(Dense(128, activation=\"tanh\"))\n","# our third dense layer\n","model.add(Dense(128, activation=\"tanh\"))\n","# our fourth dense layer\n","model.add(Dense(64, activation=\"tanh\"))\n","# last layer is the output layer.\n","model.add(Dense(10, activation=\"softmax\"))\n","\n","model.compile(optimizer=sgd_06, loss='categorical_hinge',\n","              metrics=['accuracy'])\n","\n","# setting verbose=1 prints out some results after each epoch\n","model.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y5lg3NKACYtx","executionInfo":{"status":"ok","timestamp":1654452332821,"user_tz":420,"elapsed":50735,"user":{"displayName":"Adam Astor","userId":"10506171213258147392"}},"outputId":"8e368414-1b82-4057-bb63-03dfe9646d29"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","469/469 [==============================] - 3s 6ms/step - loss: 0.7151 - accuracy: 0.6143\n","Epoch 2/20\n","469/469 [==============================] - 3s 5ms/step - loss: 0.3733 - accuracy: 0.8118\n","Epoch 3/20\n","469/469 [==============================] - 2s 5ms/step - loss: 0.3383 - accuracy: 0.8296\n","Epoch 4/20\n","469/469 [==============================] - 3s 5ms/step - loss: 0.3171 - accuracy: 0.8404\n","Epoch 5/20\n","469/469 [==============================] - 2s 5ms/step - loss: 0.3021 - accuracy: 0.8476\n","Epoch 6/20\n","469/469 [==============================] - 2s 5ms/step - loss: 0.2942 - accuracy: 0.8516\n","Epoch 7/20\n","469/469 [==============================] - 2s 5ms/step - loss: 0.2836 - accuracy: 0.8575\n","Epoch 8/20\n","469/469 [==============================] - 2s 5ms/step - loss: 0.2804 - accuracy: 0.8593\n","Epoch 9/20\n","469/469 [==============================] - 2s 5ms/step - loss: 0.2733 - accuracy: 0.8627\n","Epoch 10/20\n","469/469 [==============================] - 3s 5ms/step - loss: 0.2722 - accuracy: 0.8631\n","Epoch 11/20\n","469/469 [==============================] - 2s 5ms/step - loss: 0.2678 - accuracy: 0.8657\n","Epoch 12/20\n","469/469 [==============================] - 3s 5ms/step - loss: 0.2586 - accuracy: 0.8697\n","Epoch 13/20\n","469/469 [==============================] - 2s 5ms/step - loss: 0.2575 - accuracy: 0.8705\n","Epoch 14/20\n","469/469 [==============================] - 2s 5ms/step - loss: 0.2534 - accuracy: 0.8726\n","Epoch 15/20\n","469/469 [==============================] - 2s 5ms/step - loss: 0.2513 - accuracy: 0.8737\n","Epoch 16/20\n","469/469 [==============================] - 3s 5ms/step - loss: 0.2433 - accuracy: 0.8781\n","Epoch 17/20\n","469/469 [==============================] - 3s 5ms/step - loss: 0.2450 - accuracy: 0.8774\n","Epoch 18/20\n","469/469 [==============================] - 2s 5ms/step - loss: 0.2427 - accuracy: 0.8783\n","Epoch 19/20\n","469/469 [==============================] - 2s 5ms/step - loss: 0.2419 - accuracy: 0.8784\n","Epoch 20/20\n","469/469 [==============================] - 3s 5ms/step - loss: 0.2363 - accuracy: 0.8817\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f86d0cf1510>"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["score = model.evaluate(X_test, Y_test, verbose=0)\n","print('Test score:', score[0])\n","print('Test accuracy:', score[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ulYaN9U4Cjy4","executionInfo":{"status":"ok","timestamp":1654452333652,"user_tz":420,"elapsed":835,"user":{"displayName":"Adam Astor","userId":"10506171213258147392"}},"outputId":"5780de0b-28d8-489f-8bae-b6e9d7d04ee9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test score: 0.2683403789997101\n","Test accuracy: 0.8639000058174133\n"]}]},{"cell_type":"code","source":["model = Sequential()\n","# our first dense layer\n","model.add(Dense(256, input_shape=(784,), activation=\"tanh\"))\n","# our second dense layer\n","model.add(Dense(128, activation=\"tanh\"))\n","# our third dense layer\n","model.add(Dense(128, activation=\"tanh\"))\n","# our fourth dense layer\n","model.add(Dense(64, activation=\"tanh\"))\n","# last layer is the output layer.\n","model.add(Dense(10, activation=\"softmax\"))\n","\n","model.compile(optimizer=sgd_07, loss='categorical_hinge',\n","              metrics=['accuracy'])\n","\n","# setting verbose=1 prints out some results after each epoch\n","model.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fmm0REO5CcvE","executionInfo":{"status":"ok","timestamp":1654452385120,"user_tz":420,"elapsed":51472,"user":{"displayName":"Adam Astor","userId":"10506171213258147392"}},"outputId":"fa7cf6e2-6226-4042-ba01-8e5a96bf6456"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.7884 - accuracy: 0.1001\n","Epoch 2/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.7994 - accuracy: 0.0999\n","Epoch 3/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 4/20\n","469/469 [==============================] - 3s 6ms/step - loss: 1.7675 - accuracy: 0.1076\n","Epoch 5/20\n","469/469 [==============================] - 3s 5ms/step - loss: 1.7953 - accuracy: 0.1016\n","Epoch 6/20\n","469/469 [==============================] - 3s 5ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 7/20\n","469/469 [==============================] - 3s 5ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 8/20\n","469/469 [==============================] - 3s 5ms/step - loss: 1.7999 - accuracy: 0.1000\n","Epoch 9/20\n","469/469 [==============================] - 3s 5ms/step - loss: 1.7995 - accuracy: 0.0998\n","Epoch 10/20\n","469/469 [==============================] - 2s 5ms/step - loss: 1.4533 - accuracy: 0.2539\n","Epoch 11/20\n","469/469 [==============================] - 3s 5ms/step - loss: 0.4429 - accuracy: 0.7743\n","Epoch 12/20\n","469/469 [==============================] - 2s 5ms/step - loss: 0.3705 - accuracy: 0.8122\n","Epoch 13/20\n","469/469 [==============================] - 2s 5ms/step - loss: 0.3469 - accuracy: 0.8245\n","Epoch 14/20\n","469/469 [==============================] - 2s 5ms/step - loss: 0.3284 - accuracy: 0.8334\n","Epoch 15/20\n","469/469 [==============================] - 3s 5ms/step - loss: 0.3172 - accuracy: 0.8403\n","Epoch 16/20\n","469/469 [==============================] - 2s 5ms/step - loss: 0.3079 - accuracy: 0.8442\n","Epoch 17/20\n","469/469 [==============================] - 2s 5ms/step - loss: 0.2973 - accuracy: 0.8500\n","Epoch 18/20\n","469/469 [==============================] - 3s 6ms/step - loss: 0.2952 - accuracy: 0.8513\n","Epoch 19/20\n","469/469 [==============================] - 3s 5ms/step - loss: 0.2830 - accuracy: 0.8567\n","Epoch 20/20\n","469/469 [==============================] - 3s 5ms/step - loss: 0.2821 - accuracy: 0.8572\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f86d0b89e10>"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["score = model.evaluate(X_test, Y_test, verbose=0)\n","print('Test score:', score[0])\n","print('Test accuracy:', score[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IHM3oor3CkmO","executionInfo":{"status":"ok","timestamp":1654452385835,"user_tz":420,"elapsed":555,"user":{"displayName":"Adam Astor","userId":"10506171213258147392"}},"outputId":"859ff2f8-ce3a-4ffc-ffe7-5d75093462b0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test score: 0.33740130066871643\n","Test accuracy: 0.8309000134468079\n"]}]},{"cell_type":"code","source":["model = Sequential()\n","# our first dense layer\n","model.add(Dense(256, input_shape=(784,), activation=\"tanh\"))\n","# our second dense layer\n","model.add(Dense(128, activation=\"tanh\"))\n","# our third dense layer\n","model.add(Dense(128, activation=\"tanh\"))\n","# our fourth dense layer\n","model.add(Dense(64, activation=\"tanh\"))\n","# last layer is the output layer.\n","model.add(Dense(10, activation=\"softmax\"))\n","\n","model.compile(optimizer=sgd_08, loss='categorical_hinge',\n","              metrics=['accuracy'])\n","\n","# setting verbose=1 prints out some results after each epoch\n","model.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1Euhq3RJCdLY","executionInfo":{"status":"ok","timestamp":1654452435019,"user_tz":420,"elapsed":49188,"user":{"displayName":"Adam Astor","userId":"10506171213258147392"}},"outputId":"6b5f2e58-ad18-4ba9-a3b0-85e10c488eed"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","469/469 [==============================] - 3s 5ms/step - loss: 1.7949 - accuracy: 0.0997\n","Epoch 2/20\n","469/469 [==============================] - 3s 5ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 3/20\n","469/469 [==============================] - 2s 5ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 4/20\n","469/469 [==============================] - 2s 5ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 5/20\n","469/469 [==============================] - 2s 5ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 6/20\n","469/469 [==============================] - 2s 5ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 7/20\n","469/469 [==============================] - 2s 5ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 8/20\n","469/469 [==============================] - 2s 5ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 9/20\n","469/469 [==============================] - 2s 5ms/step - loss: 1.8030 - accuracy: 0.0980\n","Epoch 10/20\n","469/469 [==============================] - 2s 5ms/step - loss: 1.7933 - accuracy: 0.1004\n","Epoch 11/20\n","469/469 [==============================] - 2s 5ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 12/20\n","469/469 [==============================] - 2s 5ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 13/20\n","469/469 [==============================] - 2s 5ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 14/20\n","469/469 [==============================] - 2s 5ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 15/20\n","469/469 [==============================] - 2s 5ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 16/20\n","469/469 [==============================] - 2s 5ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 17/20\n","469/469 [==============================] - 2s 5ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 18/20\n","469/469 [==============================] - 2s 5ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 19/20\n","469/469 [==============================] - 2s 5ms/step - loss: 1.8000 - accuracy: 0.1000\n","Epoch 20/20\n","469/469 [==============================] - 2s 5ms/step - loss: 1.8000 - accuracy: 0.1000\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f86d09ae7d0>"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["score = model.evaluate(X_test, Y_test, verbose=0)\n","print('Test score:', score[0])\n","print('Test accuracy:', score[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L01E153mClFG","executionInfo":{"status":"ok","timestamp":1654452435649,"user_tz":420,"elapsed":633,"user":{"displayName":"Adam Astor","userId":"10506171213258147392"}},"outputId":"566c697e-4f99-4ac2-9584-e49614674e7d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test score: 1.7999999523162842\n","Test accuracy: 0.10000000149011612\n"]}]},{"cell_type":"markdown","source":["Learning Rate: 0.8\n","Test score: 1.7999999523162842\n","Test accuracy: 0.10000000149011612\n","\n","Learning Rate: 0.7\n","Test score: 0.33740130066871643\n","Test accuracy: 0.8309000134468079\n","\n","Learning Rate: 0.6\n","Test score: 0.2683403789997101\n","Test accuracy: 0.8639000058174133\n","\n","Working model (Learning Rate: 0.5)\n","Test score: 0.27018558979034424\n","Test accuracy: 0.864300012588501\n","\n","From these results, we can conclude that the optimal learning rate is 0.5.\n","\n","We now have a machine learning model that has been optimized to classify images of articles of clothing."],"metadata":{"id":"7voJfWRxDgHU"}},{"cell_type":"markdown","source":["We will run our optimized model one more time and save the weights for later use."],"metadata":{"id":"UzvhTriUn0zl"}},{"cell_type":"code","source":["model = Sequential()\n","# our first dense layer\n","model.add(Dense(256, input_shape=(784,), activation=\"tanh\"))\n","# our second dense layer\n","model.add(Dense(128, activation=\"tanh\"))\n","# our third dense layer\n","model.add(Dense(128, activation=\"tanh\"))\n","# our fourth dense layer\n","model.add(Dense(64, activation=\"tanh\"))\n","# last layer is the output layer.\n","model.add(Dense(10, activation=\"softmax\"))\n","\n","model.compile(optimizer=sgd_05, loss='categorical_hinge',\n","              metrics=['accuracy'])\n","\n","# setting verbose=1 prints out some results after each epoch\n","history = model.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6cE91FQVnyU7","executionInfo":{"status":"ok","timestamp":1655398957949,"user_tz":420,"elapsed":70214,"user":{"displayName":"Adam Astor","userId":"10506171213258147392"}},"outputId":"b498e20b-0e9f-4a0b-96be-4beab4cc7f0e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","469/469 [==============================] - 4s 7ms/step - loss: 0.6419 - accuracy: 0.6574\n","Epoch 2/20\n","469/469 [==============================] - 3s 7ms/step - loss: 0.3675 - accuracy: 0.8149\n","Epoch 3/20\n","469/469 [==============================] - 3s 7ms/step - loss: 0.3330 - accuracy: 0.8326\n","Epoch 4/20\n","469/469 [==============================] - 3s 7ms/step - loss: 0.3127 - accuracy: 0.8435\n","Epoch 5/20\n","469/469 [==============================] - 3s 7ms/step - loss: 0.3040 - accuracy: 0.8475\n","Epoch 6/20\n","469/469 [==============================] - 3s 7ms/step - loss: 0.2895 - accuracy: 0.8543\n","Epoch 7/20\n","469/469 [==============================] - 3s 7ms/step - loss: 0.2802 - accuracy: 0.8592\n","Epoch 8/20\n","469/469 [==============================] - 3s 7ms/step - loss: 0.2759 - accuracy: 0.8613\n","Epoch 9/20\n","469/469 [==============================] - 3s 7ms/step - loss: 0.2700 - accuracy: 0.8645\n","Epoch 10/20\n","469/469 [==============================] - 3s 7ms/step - loss: 0.2659 - accuracy: 0.8666\n","Epoch 11/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.2593 - accuracy: 0.8696\n","Epoch 12/20\n","469/469 [==============================] - 3s 7ms/step - loss: 0.2559 - accuracy: 0.8711\n","Epoch 13/20\n","469/469 [==============================] - 3s 7ms/step - loss: 0.2534 - accuracy: 0.8727\n","Epoch 14/20\n","469/469 [==============================] - 3s 7ms/step - loss: 0.2466 - accuracy: 0.8764\n","Epoch 15/20\n","469/469 [==============================] - 3s 7ms/step - loss: 0.2440 - accuracy: 0.8774\n","Epoch 16/20\n","469/469 [==============================] - 3s 7ms/step - loss: 0.2443 - accuracy: 0.8772\n","Epoch 17/20\n","469/469 [==============================] - 3s 7ms/step - loss: 0.2392 - accuracy: 0.8801\n","Epoch 18/20\n","469/469 [==============================] - 4s 9ms/step - loss: 0.2334 - accuracy: 0.8829\n","Epoch 19/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.2309 - accuracy: 0.8842\n","Epoch 20/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.2318 - accuracy: 0.8836\n"]}]},{"cell_type":"code","source":["score = model.evaluate(X_test, Y_test, verbose=0)\n","print('Test score:', score[0])\n","print('Test accuracy:', score[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v1jE5olNn0E5","executionInfo":{"status":"ok","timestamp":1655398958940,"user_tz":420,"elapsed":995,"user":{"displayName":"Adam Astor","userId":"10506171213258147392"}},"outputId":"b7e00662-591b-4bf5-f0b5-6648cba809d1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test score: 0.27371034026145935\n","Test accuracy: 0.8616999983787537\n"]}]},{"cell_type":"code","source":["acc = history.history['accuracy']\n","loss = history.history['loss']\n","\n","epochs_range = range(20)\n","\n","plt.figure(figsize=(15, 15))\n","plt.subplot(2, 2, 1)\n","plt.plot(epochs_range, acc, label='Training Accuracy')\n","plt.legend(loc='lower right')\n","plt.title('TrainingAccuracy')\n","\n","plt.subplot(2, 2, 2)\n","plt.plot(epochs_range, loss, label='Training Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training Loss')\n","plt.show()"],"metadata":{"id":"wI44ZPS4Cmhl","colab":{"base_uri":"https://localhost:8080/","height":435},"executionInfo":{"status":"ok","timestamp":1654630087561,"user_tz":420,"elapsed":825,"user":{"displayName":"Adam Astor","userId":"10506171213258147392"}},"outputId":"d1bc0526-268a-40db-c996-ded6409e9d4a"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1080x1080 with 2 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["Now to evaluate the model we will get the accuracy score, precision, recall, f1-score and confusion matrix."],"metadata":{"id":"mV9bUlh7Dfok"}},{"cell_type":"code","source":["#Preparing prediction variables for analysis\n","y_predict=model.predict(X_test) \n","classes_x=np.argmax(y_predict,axis=1)\n","\n","print(classes_x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vB-NUTK4pCpO","executionInfo":{"status":"ok","timestamp":1655398959576,"user_tz":420,"elapsed":642,"user":{"displayName":"Adam Astor","userId":"10506171213258147392"}},"outputId":"69dd4e37-b86c-4d77-a3d7-c4f09ed24e7c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[9 2 1 ... 8 1 5]\n"]}]},{"cell_type":"markdown","source":["A confusion matrix is a summary of prediction results on a classification problem.\n","\n","The number of correct and incorrect predictions are summarized with count values and broken down by each class. This is the key to the confusion matrix.\n","\n","The confusion matrix shows the ways in which your classification model\n","is confused when it makes predictions.\n","\n","It gives you insight not only into the errors being made by your classifier but more importantly the types of errors that are being made.\n","\n","It is this breakdown that overcomes the limitation of using classification accuracy alone."],"metadata":{"id":"dLG9-xqV_97R"}},{"cell_type":"code","source":["print(confusion_matrix(y_test, classes_x))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dtlpowl2pNWV","executionInfo":{"status":"ok","timestamp":1654638818832,"user_tz":420,"elapsed":454,"user":{"displayName":"Adam Astor","userId":"10506171213258147392"}},"outputId":"9169271d-cca7-4ef8-b2ea-6aa01a627373"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[870   2  19  11  13   0  73   1  11   0]\n"," [  3 966   2  17   7   0   3   0   2   0]\n"," [ 18   3 775   7 160   1  32   0   4   0]\n"," [ 43  18  17 807  79   0  31   0   5   0]\n"," [  0   1  82   9 881   0  24   0   3   0]\n"," [  0   0   0   1   0 951   0  34   2  12]\n"," [170   3 117  22 143   0 529   0  16   0]\n"," [  0   0   0   0   0  27   0 966   0   7]\n"," [  2   0   5   2   7   2   4   5 973   0]\n"," [  0   0   0   0   0   9   0  78   1 912]]\n"]}]},{"cell_type":"markdown","source":["Accuracy can be defined as the ratio of the number of correctly classified cases to the total of cases under evaluation. The best value of accuracy is 1 and the worst value is 0.\n","\n"],"metadata":{"id":"qXVXRRYXKQhQ"}},{"cell_type":"markdown","source":["Precision is a value that tells you what proportion of positive predictions are correct. That is, if the model has a precision of 0.75, then 75% of its positive predictions are correct."],"metadata":{"id":"Y0rQWO3H-kNg"}},{"cell_type":"markdown","source":["The recall is calculated as the ratio between the numbers of Positive samples correctly classified as Positive to the total number of Positive samples. The recall measures the model's ability to detect positive samples. The higher the recall, the more positive samples detected."],"metadata":{"id":"Jxfm_wLz-qdx"}},{"cell_type":"markdown","source":["F1-score is defined as the harmonic mean between precision and recall. It is used as a statistical measure to rate performance. F1-score takes both precision and recall into account, which also means it accounts for both FPs and FNs."],"metadata":{"id":"nzCEyEApERpJ"}},{"cell_type":"code","source":["report = classification_report(y_test, classes_x, output_dict=True)\n","\n","df_classification_report = pd.DataFrame(report).transpose()\n","\n","df_classification_report['classes'] = df_classification_report.index\n","\n","df_classification_report"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":457},"id":"5aJ4oliT8Hiy","executionInfo":{"status":"ok","timestamp":1654883164671,"user_tz":420,"elapsed":11,"user":{"displayName":"Adam Astor","userId":"10506171213258147392"}},"outputId":"cf2e2102-963f-447b-a688-d975d2778607"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["              precision  recall  f1-score     support       classes\n","0              0.807322  0.8380  0.822375   1000.0000             0\n","1              0.989648  0.9560  0.972533   1000.0000             1\n","2              0.833116  0.6390  0.723260   1000.0000             2\n","3              0.860236  0.8740  0.867063   1000.0000             3\n","4              0.631872  0.9080  0.745178   1000.0000             4\n","5              0.975480  0.9150  0.944272   1000.0000             5\n","6              0.738186  0.5780  0.648345   1000.0000             6\n","7              0.913662  0.9630  0.937683   1000.0000             7\n","8              0.960486  0.9480  0.954202   1000.0000             8\n","9              0.935897  0.9490  0.942403   1000.0000             9\n","accuracy       0.856800  0.8568  0.856800      0.8568      accuracy\n","macro avg      0.864591  0.8568  0.855732  10000.0000     macro avg\n","weighted avg   0.864591  0.8568  0.855732  10000.0000  weighted avg"],"text/html":["\n","  <div id=\"df-e7660020-10ed-4f74-8f35-058605b7b09b\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>precision</th>\n","      <th>recall</th>\n","      <th>f1-score</th>\n","      <th>support</th>\n","      <th>classes</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.807322</td>\n","      <td>0.8380</td>\n","      <td>0.822375</td>\n","      <td>1000.0000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.989648</td>\n","      <td>0.9560</td>\n","      <td>0.972533</td>\n","      <td>1000.0000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.833116</td>\n","      <td>0.6390</td>\n","      <td>0.723260</td>\n","      <td>1000.0000</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.860236</td>\n","      <td>0.8740</td>\n","      <td>0.867063</td>\n","      <td>1000.0000</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.631872</td>\n","      <td>0.9080</td>\n","      <td>0.745178</td>\n","      <td>1000.0000</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.975480</td>\n","      <td>0.9150</td>\n","      <td>0.944272</td>\n","      <td>1000.0000</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.738186</td>\n","      <td>0.5780</td>\n","      <td>0.648345</td>\n","      <td>1000.0000</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.913662</td>\n","      <td>0.9630</td>\n","      <td>0.937683</td>\n","      <td>1000.0000</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.960486</td>\n","      <td>0.9480</td>\n","      <td>0.954202</td>\n","      <td>1000.0000</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.935897</td>\n","      <td>0.9490</td>\n","      <td>0.942403</td>\n","      <td>1000.0000</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>accuracy</th>\n","      <td>0.856800</td>\n","      <td>0.8568</td>\n","      <td>0.856800</td>\n","      <td>0.8568</td>\n","      <td>accuracy</td>\n","    </tr>\n","    <tr>\n","      <th>macro avg</th>\n","      <td>0.864591</td>\n","      <td>0.8568</td>\n","      <td>0.855732</td>\n","      <td>10000.0000</td>\n","      <td>macro avg</td>\n","    </tr>\n","    <tr>\n","      <th>weighted avg</th>\n","      <td>0.864591</td>\n","      <td>0.8568</td>\n","      <td>0.855732</td>\n","      <td>10000.0000</td>\n","      <td>weighted avg</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e7660020-10ed-4f74-8f35-058605b7b09b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-e7660020-10ed-4f74-8f35-058605b7b09b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-e7660020-10ed-4f74-8f35-058605b7b09b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["The data labels corrsepond to the following clothing articles:\n","\n","    0 T-shirt/top\n","    1 Trouser\n","    2 Pullover\n","    3 Dress\n","    4 Coat\n","    5 Sandal\n","    6 Shirt\n","    7 Sneaker\n","    8 Bag\n","    9 Ankle boot\n","\n","---\n","\n"],"metadata":{"id":"QgwwDU2ULh_o"}},{"cell_type":"markdown","source":["From the confusion matrix and classification report above, we can see that the model struggled most with classifying Class 6 (Shirt) and performed best at predicting Class 1 (Trouser).\n","\n"],"metadata":{"id":"iIHsDHJyD53j"}},{"cell_type":"markdown","source":["To confirm our results, we will use cross-validation.\n","\n","So far, I have been using a train-test split to reserve a portion of the data for testing. I do this so that I have some previously unseen data to test the model. If I train and test with the same data, I run the risk of overfitting the model to the training data.\n","\n","But there is still a risk of overfitting to the test data itself. If I tune my model to perform well on the test data, what guarantee do I have that it will continue to perform as well on new data? Also, I know that the training algorithm is susceptible to small changes in the data."],"metadata":{"id":"T3q3i38dOV0i"}},{"cell_type":"code","source":["from sklearn.model_selection import StratifiedKFold\n","\n","# fix random seed for reproducibility\n","seed = 7\n","np.random.seed(seed)\n","\n","# define 10-fold cross validation test harness\n","kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n","cvscores = []\n","for train, test in kfold.split(X_train, y_train):\n","  # Fit the model\n","\tmodel.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=0)\n","\t# evaluate the model\n","\tscores = model.evaluate(X_test, Y_test, verbose=0)\n","\tprint(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n","\tcvscores.append(scores[1] * 100)\n","print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"],"metadata":{"id":"Ix-LwOJTOVil","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654801730201,"user_tz":420,"elapsed":562796,"user":{"displayName":"Adam Astor","userId":"10506171213258147392"}},"outputId":"cd4bcfa6-ded2-49b7-ba51-8283bf0ea934"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["accuracy: 87.24%\n","accuracy: 86.82%\n","accuracy: 86.26%\n","accuracy: 86.27%\n","accuracy: 86.38%\n","accuracy: 85.81%\n","accuracy: 85.57%\n","accuracy: 84.84%\n","accuracy: 86.51%\n","accuracy: 85.68%\n","86.14% (+/- 0.65%)\n"]}]},{"cell_type":"code","source":["#df_classification_report.drop('classes', axis=1, inplace=True)\n","\n","#df_classification_report.drop('support', axis=1, inplace=True)\n","plt.figure(figsize=(20,10))\n","plt.imshow(df_classification_report, cmap =\"RdYlBu\")\n","plt.colorbar()\n","plt.xticks(range(len(df_classification_report.columns)), df_classification_report.columns)\n","plt.yticks(range(len(df_classification_report.index)), df_classification_report.index)\n","plt.grid(b=None)\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":592},"id":"R-qVGWEgtz3y","executionInfo":{"status":"ok","timestamp":1654889100204,"user_tz":420,"elapsed":757,"user":{"displayName":"Adam Astor","userId":"10506171213258147392"}},"outputId":"f9493ff1-0046-4306-a6b4-1bc7b53b76cf"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1440x720 with 2 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["Now that we have a working model that has been tuned and evaluated, we can make some predictions on new images of clothing articles to see if it can accurately classify based on the training it has received so far."],"metadata":{"id":"MlVygXchXywi"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ut2uBa9ebPe4","executionInfo":{"status":"ok","timestamp":1655398981326,"user_tz":420,"elapsed":21753,"user":{"displayName":"Adam Astor","userId":"10506171213258147392"}},"outputId":"e847b5a9-bf3e-4875-9eca-42c9d779ce71"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["Below, we have a sample image that the model has never seen before. Let's test our model to see if it can classify the image correctly. We are looking for a result of 2 representing the class of \"Pullover\"."],"metadata":{"id":"mwuoFXEBjXvg"}},{"cell_type":"code","source":["%pylab inline\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","img = mpimg.imread('/content/drive/MyDrive/python_for_data_scientists/Capstone 4 Final Project/V2/Prediction Sample Image/sample_image.png')\n","imgplot = plt.imshow(img)\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":288},"id":"NUuzxxsHjLXM","executionInfo":{"status":"ok","timestamp":1655398982815,"user_tz":420,"elapsed":1495,"user":{"displayName":"Adam Astor","userId":"10506171213258147392"}},"outputId":"87b0cf5a-1f01-43f3-fc6b-2f1242edcf63"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Populating the interactive namespace from numpy and matplotlib\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["# make a prediction for a new image.\n","from keras.preprocessing.image import load_img\n","from keras.preprocessing.image import img_to_array\n","from keras.models import load_model\n"," \n","# load and prepare the image\n","def load_image(filename):\n","\t# load the image\n","\timg = load_img(filename, grayscale=True, target_size=(28, 28))\n","\t# convert to array\n","\timg = img_to_array(img)\n","\t# reshape into a single sample with 1 channel\n","\timg = img.reshape(1, input_dim)\n","\t# prepare pixel data\n","\timg = img.astype('float32')\n","\timg = img / 255.0\n","\treturn img\n"," \n","# load an image and predict the class\n","def run_example():\n","\t# load the image\n","  img = load_image('/content/drive/MyDrive/python_for_data_scientists/Capstone 4 Final Project/V2/Prediction Sample Image/sample_image.png')\n","\t# load model\n","\t#model = load_model('final_model.h5')\n","\t# predict the class\n","\t#result = model.predict_classes(img, verbose=1)\n","  predict_x=model.predict(img)\n","  result=np.argmax(predict_x,axis=1)\n","  print(result[0])\n"," \n","# entry point, run the example\n","run_example()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9_G3AwDlzIJI","executionInfo":{"status":"ok","timestamp":1655415743045,"user_tz":420,"elapsed":183,"user":{"displayName":"Adam Astor","userId":"10506171213258147392"}},"outputId":"408bca13-be3b-45d2-c1fe-7675eb56376c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2\n"]}]},{"cell_type":"markdown","source":["Correct! The image was correctly identified as a Pullover."],"metadata":{"id":"DZXr0SeJkGQI"}},{"cell_type":"markdown","source":["We can conclude that we have a robust image classification model that can accurately identify images of clothing articles in the Fashion MNIST dataset.\n","\n","The Fashion MNIST contains images of 10 different classes of types of clothing: T-shirt/top, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag and Ankle boot. While the classes do not include every type of clothing imaginable, they do cover a large amount of common clothing types that are seen and worn worldwide. Given the types of clothing the model is trained on, there are many possible use cases for the image classification model.\n","\n","This model could be used to identify clothes for a blind person to wear through their phone, or for security and asset protection purposes at a department store by the security cameras. This model can help to organize a clothing donation center or to make an online clothing store search function more efficient.\n","\n","It will run in a production environment by utilizing the code two cells above this cell. Simply replace the filepath with the filepath of the image you wish to classify and run the cell. The predicted class of the image will print, telling you which type of clothing article is shown in the image.\n","\n","To maintain this project going forward, the user will need to make sure that all modules are updated and their calls are working appropriately. \n","\n","We started with a sequential model for image classification. Through testing variables like number of layers, neurons, activation functions, etc, we have settled on a 5-layer Sequential model that has 256, 128, 128, 64 and 10 neurons respectively and uses hyperbolic tangent as it's activation function. The model uses an SGD optimizer with a learning rate of 0.5 and a categorical hinge loss function. The batch size is 128 and is set to 20 epochs for the training."],"metadata":{"id":"D-PE7EBAXZSd"}}]}